%!TEX root = ../main.tex

\chapter{Future work}

In this thesis project I have thus far only implemented code generation for JSON. The library \fsharpdata\footnote{\url{http://fsharp.github.io/FSharp.Data/}} has type providers for JSON, CSV, HTML and XML. Like \fsharpdata, the code generation in my project is generic over inferred types. Thus, writing similar projects in Rust for other data formats should be able to reuse large amounts of the code I have written. Considering the benefits and added complexity of multiple interfaces I do not think a single project like \fsharpdata\ is the right approach for an extension of my code.

\fsharpdata\ supports a solution for heterogenous collections to avoid inferring any types for some cases. I have not implemented this functionality (or tagged any-types). Such functionality would be very useful in certain specific cases. A possible way to introduce this functionality while not coming into conflict with «Serde» would be to use enums for tagged any-types along with simple helper functions using ‹filter_map›.

«Serde» 1.0 was recently released and supports zero-copy deserialization. What this means is that if data is deserialized from something that is already in memory, no new memory is allocated on the heap, and the new data structure instead references the existing memory. In some cases this can be very beneficial, and it might be worthwhile to implement support for this feature in the code generated by «json_typegen». However, in most of my own trials of actually deserializing, I have been working with streams of data, and as such have allocated memory only for the end product, not the source I was deserializing from.

As mentioned in the introduction JSON is a schemaless data format. There is however a separate schema format -- JSON Schema -- that has emerged. It is likely that similar code generation techniques to those used in this project could be applied to JSON Schema. There are however some additional challenges when generating code for JSON Schema:

\begin{enumerate}
  \item It seems to me though that a lot of the people/websites actually using JSON Schema (often in Swagger/OpenAPI) don't actually use it according to the specification. As an example; many completely omit the "required" field that specify which fields of an object are not nullable. In my opinion this defeats some of the point of a schema, as it leaves us unable to generate code that is both safe and ergonomic without inspecting the data itself and making assumptions based on it.
  \item JSON Schema also has some challenges for code generation in that it can easily represent types which are very hard to represent (at least with serde, the most common serialization/deserialization library for Rust), so it may require actually writing the deserialization code more or less specifically for any hypothetical JSON Schema library. The references in JSON Schema also means that a naive tree walk is not quite enough (though not far from it).
\end{enumerate}

% OpenAPI

% Tagged JSON: https://www.tjson.org
