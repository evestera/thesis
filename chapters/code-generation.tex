%!TEX root = ../main.tex

\chapter{Code generation}
\label{sec:code-generation}

Once a JSON sample has been retrieved and parsed using «serde_json» into the catchall type ‹serde_json::Value›, «json_typegen» is ready to begin inference and code generation. In this chapter we will look at the details of these three stages:

\begin{itemize}
  \item First a generalized \say{shape} is inferred from the JSON values.
  \item Then this inference is enhanced in intermediary passes.
  \item Finally Rust code is generated based on the inferred shapes.
\end{itemize}

First I will present the basic version of the inference algorithm and code generation, before looking at how this basic system can be extended in various ways.

\section{Shape inference}

The shape inference is based on the algorithms used in \fsharpdata\ as presented in the paper \emph{Types from Data: Making Structured Data First-class Citizens in F\#}\cite{fsharp-types-from-data}. As done in this paper I will use the term shape for the intermediate representation of the inference data, to avoid confusion with actual programming language types.

% Describe how shapes and types differ

The basic algorithm has two main functions, $\shap$ and $\csh$.

$\shap$, shown in figure~\ref{fig:shap} takes as its input the parsed ‹serde_json::Value› and produces a shape.

\begin{figure}[ht!]
\begin{align*}
\shap(‹Null›)          &= ‹null› \\
\shap(‹Bool(›a‹)›)     &= ‹bool› \\
\shap(‹Number(›a‹)›)   &= \left\{\begin{array}{ll}
  ‹int›   & \text{if } a \in \mathbb{Z} \\
  ‹float› & \text{otherwise}
\end{array}\right.\\
\shap(‹String(›a‹)›)   &= ‹string› \\
\shap(‹Array(›[\ ]‹)›) &= [\ ] \\
\shap(‹Array(›[a_1, a_2, \cdots, a_n]‹)›) &= [\fold(\csh, \shap(a_1), [\shap(a_2), \cdots, \shap(a_n)])] \\
\shap(‹Object(›\{ k_1 : v_1, \cdots, k_n : v_n \}‹)›) &= \{ k_1 : \shap(v_1), \cdots, k_n : \shap(v_n) \}
\end{align*}
\caption{$\shap$, the function mapping JSON values to shapes}
\label{fig:shap}
\end{figure}

\begin{figure}[ht!]
\begin{align*}
\csh(a, a)               &=  a               & (eq) \\
\csh(‹int›, ‹float›)     &= ‹float›          & (num) \\
\csh(a, ‹null›)          &= \opt(a)          & (null) \\
\csh(a, ‹optional(›b‹)›) &= \opt(\csh(a, b)) & (opt) \\
\csh([\ ], [a])          &= [a]              & (empty) \\
\csh([a], [b])           &= [\csh(a, b)]     & (arr) \\
\csh(a = \{ \cdots \}, b = \{ \cdots \}) &= \cfs(a, b) & (obj) \\
\csh(a, b)               &= ‹any›            & (any)
\end{align*}
\caption{$\csh$, the common shape function}
\label{fig:csh}
\end{figure}

\begin{figure}[ht!]
\begin{align*}
\opt(‹null›) &= ‹null› \\
\opt(‹any›)  &= ‹any› \\
\opt(‹optional(›a‹)›) &= ‹optional(›a‹)› \\
\opt(a) &= ‹optional(›a‹)›
\end{align*}
\caption{$\opt$, the function ensuring optionality/nullability of shapes}
\label{fig:opt}
\end{figure}

\begin{figure}[ht!]
\begin{gather*}
\cfs(a = \{ k_1 : v_1, \cdots, k_n : v_n \}, b = \{ k_1 : v'_1, \cdots, k_n : v'_n \}) = \\
\{ k_1 : \left( \begin{array}{ll}
  \csh(v_1, v'_1) & \text{if } k_1 \in a \cap b \\
  \opt(v_1) & \text{if } k_1 \notin b \\
  \opt(v'_1) & \text{if } k_1 \notin a
\end{array}\right), \cdots, k_n : \left( \begin{array}{ll}
  \csh(v_n, v'_n) & \text{if } k_n \in a \cap b \\
  \opt(v_n) & \text{if } k_n \notin b \\
  \opt(v'_n) & \text{if } k_n \notin a
\end{array}\right) \}
\end{gather*}
\caption{$\cfs$, the function for finding the common shape of two records}
\label{fig:ufi}
\end{figure}

\section{Intermediary passes}

In the basic version of the algorithm, there are no intermediary passes. These passes are mainly a result of extensions of the algorithm. The extensions come about for two main reasons: Improving the code to more closely resemble hand-written code, and adding configurability of the inference and code generation.

We will look at these extensions, and their consequences for the algorithm in section~\ref{sec:extensions}.

\section{Generating Rust types}

\section{Code generation dilemmas}
\label{sec:design-considerations}

When inferring shapes and generating code based on JSON one has to work with incomplete data. As such it is unavoidable that some choices have to be made. Unfortunately several of these choices do not present any alternative that is clearly better in all cases.

\placeholder{Option vs Enum, detection of entirely separate types}

\placeholder{Option vs Default, missing fields}

\placeholder{Extra fields}

\begin{listing}[ht!]
\begin{minted}{json}
[
  {
    "a": 1
  },
  {
    "b": 1
  }
]
\end{minted}
\caption{JSON Dilemma \#1}
\label{lst:json-dilemma-1}
\end{listing}

\begin{listing}[ht!]
\begin{minted}{rust}
struct S {
    a: Option<i32>,
    b: Option<i32>,
}

enum E {
    A { a: i32 },
    B { b: i32 },
}
\end{minted}
\caption{JSON Dilemma \#1 - Two solutions}
\label{lst:json-dilemma-1-rs}
\end{listing}

\section{Extensions}
\label{sec:extensions}

\placeholder{Describe (and maybe show) extension of inference to AnyOf / tagged any types.}

\placeholder{Detection of tuple types.}

\placeholder{Maps. "Impossible" to infer, but can be hinted. Values in a map are essentially already nullable.}

\placeholder{Inferring types from multiple samples/sample-sets but ensuring that they can still work together. Show how this can already be done to a certain extent using \url{https://github.com/lloydmeta/frunk}}

\placeholder{Collapsing identical shapes}
